{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWqdi0bZStYLqvOWYwuBNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aj1365/WetMapFormer/blob/main/WetMapFormer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afzk2kmFDj3v"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization,GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Input\n",
        "from keras.models import Model\n",
        "#from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For running in python 2.x\n",
        "from __future__ import print_function, unicode_literals\n",
        "from __future__ import absolute_import, division\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Dropout, Dense, RepeatVector, Lambda, Reshape, Conv3D, Conv2D, Flatten, InputSpec\n",
        "from keras.layers import BatchNormalization, Concatenate, Multiply, Add, Conv2DTranspose, GlobalAveragePooling2D, MaxPool2D\n",
        "from keras.layers.advanced_activations import LeakyReLU, Softmax\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "2arQoiKwDomU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "8vdVkBxuDopV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(name):\n",
        "    \n",
        "    data_path = os.path.join(os.getcwd(),'E:/')\n",
        "   \n",
        "    if name == 'SA1':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'SA1.mat'))['SA1']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'SA1_gt.mat'))['SA1_gt']\n",
        "    if name == 'SA2':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'SA2.mat'))['SA2']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'SA2_gt.mat'))['SA2_gt']\n",
        "    if name == 'SA3':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'SA3.mat'))['SA3']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'SA3_gt.mat'))['SA3_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "Oa24kqezDrw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## GLOBAL VARIABLES\n",
        "test_ratio = 0.3\n",
        "windowSize = 8"
      ],
      "metadata": {
        "id": "Plaeu2MPDrz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "l2uX3avVDr3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "metadata": {
        "id": "p8l_SZr4Dr6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
        "    margin = int((windowSize) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "metadata": {
        "id": "-9YtY8YADost"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'SA1'\n",
        "X1 , Y1 = loadData(dataset)\n",
        "#X[X>100000]=-1\n",
        "X1[np.isnan(X1)]=-1\n",
        "X1[X1<-1000]=-1\n",
        "X1.shape"
      ],
      "metadata": {
        "id": "fqePxT76D0pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'SA2'\n",
        "X2 , Y2 = loadData(dataset)\n",
        "#X[X>100000]=-1\n",
        "X2[np.isnan(X2)]=-1\n",
        "X2[X2<-1000]=-1\n",
        "X2.shape"
      ],
      "metadata": {
        "id": "VXUQqdO4D0s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'SA3'\n",
        "X3 , Y3 = loadData(dataset)\n",
        "#X[X>100000]=-1\n",
        "X3[np.isnan(X3)]=-1\n",
        "X3[X3<-1000]=-1\n",
        "X3.shape"
      ],
      "metadata": {
        "id": "56jV5zZWD0vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1, Y1 = createImageCubes(X1, Y1, windowSize=windowSize)\n",
        "X1.shape, Y1.shape"
      ],
      "metadata": {
        "id": "1p4NkzuOD0yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2, Y2 = createImageCubes(X2, Y2, windowSize=windowSize)\n",
        "X2.shape, Y2.shape"
      ],
      "metadata": {
        "id": "N5TPbzo3D01n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X3, Y3 = createImageCubes(X3, Y3, windowSize=windowSize)\n",
        "X3.shape, Y3.shape"
      ],
      "metadata": {
        "id": "np46EKr2Dovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((X1, X2, X3) , axis = 0)\n",
        "Y = np.concatenate((Y1, Y2, Y3) , axis = 0)\n",
        "\n",
        "X.shape,Y.shape"
      ],
      "metadata": {
        "id": "eAKBPq_FDoy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cqD-LgeD-YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, Y, test_ratio)\n",
        "\n",
        "np.min(ytrain), np.max(ytrain)"
      ],
      "metadata": {
        "id": "t5Pz4HK9D-bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ES8ly7ioD-eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain= Xtrain.reshape((Xtrain.shape[0],windowSize,windowSize,16))\n",
        "image_size=8\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(Xtrain)"
      ],
      "metadata": {
        "id": "blv8b1uaD-hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from keras_cv_attention_models.attention_layers import (\n",
        "    activation_by_name,\n",
        "    ChannelAffine,\n",
        "    conv2d_no_bias,\n",
        "    depthwise_conv2d_no_bias,\n",
        "    drop_block,\n",
        "    #MixupToken,\n",
        "    mlp_block,\n",
        "    output_block,\n",
        "    add_pre_post_process,\n",
        ")\n",
        "from keras_cv_attention_models.download_and_load import reload_model_weights\n"
      ],
      "metadata": {
        "id": "tlIEhkoAEC0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv_attention_models.attention_layers import (\n",
        "    ChannelAffine,\n",
        "    CompatibleExtractPatches,\n",
        "    conv2d_no_bias,\n",
        "    drop_block,\n",
        "    layer_norm,\n",
        "    mlp_block,\n",
        "    output_block,\n",
        "    add_pre_post_process,\n",
        ")\n",
        "from keras_cv_attention_models.download_and_load import reload_model_weights\n"
      ],
      "metadata": {
        "id": "BAiCqywlEC3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_NORM_DECAY = 0.9\n",
        "BATCH_NORM_EPSILON = 1e-5\n",
        "LAYER_NORM_EPSILON = 1e-6"
      ],
      "metadata": {
        "id": "txetqPZ1EC6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadRelativePositionalKernelBias(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_height=-1, is_heads_first=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_height, self.is_heads_first = input_height, is_heads_first\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        blocks, num_heads = (input_shape[2], input_shape[1]) if self.is_heads_first else (input_shape[1], input_shape[2])\n",
        "        size = int(tf.math.sqrt(float(input_shape[-1])))\n",
        "        height = self.input_height if self.input_height > 0 else int(tf.math.sqrt(float(blocks)))\n",
        "        width = blocks // height\n",
        "        pos_size = 2 * size - 1\n",
        "        initializer = tf.initializers.truncated_normal(stddev=0.02)\n",
        "        self.pos_bias = self.add_weight(name=\"positional_embedding\", shape=(num_heads, pos_size * pos_size), initializer=initializer, trainable=True)\n",
        "\n",
        "        idx_hh, idx_ww = tf.range(0, size), tf.range(0, size)\n",
        "        coords = tf.reshape(tf.expand_dims(idx_hh, -1) * pos_size + idx_ww, [-1])\n",
        "        bias_hh = tf.concat([idx_hh[: size // 2], tf.repeat(idx_hh[size // 2], height - size + 1), idx_hh[size // 2 + 1 :]], axis=-1)\n",
        "        bias_ww = tf.concat([idx_ww[: size // 2], tf.repeat(idx_ww[size // 2], width - size + 1), idx_ww[size // 2 + 1 :]], axis=-1)\n",
        "        bias_hw = tf.expand_dims(bias_hh, -1) * pos_size + bias_ww\n",
        "        bias_coords = tf.expand_dims(bias_hw, -1) + coords\n",
        "        bias_coords = tf.reshape(bias_coords, [-1, size**2])[::-1]  # torch.flip(bias_coords, [0])\n",
        "\n",
        "        bias_coords_shape = [bias_coords.shape[0]] + [1] * (len(input_shape) - 4) + [bias_coords.shape[1]]\n",
        "        self.bias_coords = tf.reshape(bias_coords, bias_coords_shape)  # [height * width, 1 * n, size * size]\n",
        "        if not self.is_heads_first:\n",
        "            self.transpose_perm = [1, 0] + list(range(2, len(input_shape) - 1))  # transpose [num_heads, height * width] -> [height * width, num_heads]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.is_heads_first:\n",
        "            return inputs + tf.gather(self.pos_bias, self.bias_coords, axis=-1)\n",
        "        else:\n",
        "            return inputs + tf.transpose(tf.gather(self.pos_bias, self.bias_coords, axis=-1), self.transpose_perm)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        base_config.update({\"input_height\": self.input_height, \"is_heads_first\": self.is_heads_first})\n",
        "        return base_config"
      ],
      "metadata": {
        "id": "gLy61kawEC-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def LWA(\n",
        "    inputs, kernel_size=3, num_heads=2, key_dim=0, out_weight=True, qkv_bias=True, out_bias=True, attn_dropout=0, output_dropout=0, name=None\n",
        "):\n",
        "    \n",
        "    _, hh, ww, cc = inputs.shape\n",
        "    key_dim = key_dim if key_dim > 0 else cc // num_heads\n",
        "    qk_scale = 1.0 / (float(key_dim) ** 0.5)\n",
        "    out_shape = cc\n",
        "    qkv_out = num_heads * key_dim\n",
        "\n",
        "    should_pad_hh, should_pad_ww = max(0, kernel_size - hh), max(0, kernel_size - ww)\n",
        "    if should_pad_hh or should_pad_ww:\n",
        "        inputs = tf.pad(inputs, [[0, 0], [0, should_pad_hh], [0, should_pad_ww], [0, 0]])\n",
        "        _, hh, ww, cc = inputs.shape\n",
        "\n",
        "    qkv = keras.layers.Dense(qkv_out * 3, use_bias=qkv_bias, name=name and name + \"qkv\")(inputs)\n",
        "    query, key_value = tf.split(qkv, [qkv_out, qkv_out * 2], axis=-1)  # Matching weights from PyTorch\n",
        "    query = tf.expand_dims(tf.reshape(query, [-1, hh * ww, num_heads, key_dim]), -2)  # [batch, hh * ww, num_heads, 1, key_dim]\n",
        "\n",
        "    key_value = CompatibleExtractPatches(sizes=kernel_size, strides=1, padding=\"VALID\", compressed=False)(key_value)\n",
        "    padded = (kernel_size - 1) // 2\n",
        "\n",
        "    key_value = tf.concat([tf.repeat(key_value[:, :1], padded, axis=1), key_value, tf.repeat(key_value[:, -1:], padded, axis=1)], axis=1)\n",
        "    key_value = tf.concat([tf.repeat(key_value[:, :, :1], padded, axis=2), key_value, tf.repeat(key_value[:, :, -1:], padded, axis=2)], axis=2)\n",
        "\n",
        "    key_value = tf.reshape(key_value, [-1, kernel_size * kernel_size, key_value.shape[-1]])\n",
        "    key, value = tf.split(key_value, 2, axis=-1)  # [batch * block_height * block_width, kernel_size * kernel_size, key_dim]\n",
        "    key = tf.transpose(tf.reshape(key, [-1, key.shape[1], num_heads, key_dim]), [0, 2, 3, 1])  # [batch * hh*ww, num_heads, key_dim, kernel_size * kernel_size]\n",
        "    key = tf.reshape(key, [-1, hh * ww, num_heads, key_dim, kernel_size * kernel_size])  # [batch, hh*ww, num_heads, key_dim, kernel_size * kernel_size]\n",
        "    value = tf.transpose(tf.reshape(value, [-1, value.shape[1], num_heads, key_dim]), [0, 2, 1, 3])\n",
        "    value = tf.reshape(value, [-1, hh * ww, num_heads, kernel_size * kernel_size, key_dim])  # [batch, hh*ww, num_heads, kernel_size * kernel_size, key_dim]\n",
        "\n",
        "    attention_scores = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([query, key]) * qk_scale\n",
        "    attention_scores = MultiHeadRelativePositionalKernelBias(input_height=hh, name=name and name + \"pos\")(attention_scores)\n",
        "    attention_scores = keras.layers.Softmax(axis=-1, name=name and name + \"attention_scores\")(attention_scores)\n",
        "    attention_scores = keras.layers.Dropout(attn_dropout, name=name and name + \"attn_drop\")(attention_scores) if attn_dropout > 0 else attention_scores\n",
        "\n",
        "\n",
        "    attention_output = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([attention_scores, value])\n",
        "    attention_output = tf.reshape(attention_output, [-1, hh, ww, num_heads * key_dim])\n",
        "\n",
        "\n",
        "    if should_pad_hh or should_pad_ww:\n",
        "        \n",
        "        attention_output = attention_output[:, : hh - should_pad_hh, : ww - should_pad_ww, :]\n",
        "\n",
        "    if out_weight:\n",
        "        \n",
        "        attention_output = keras.layers.Dense(out_shape, use_bias=out_bias, name=name and name + \"output\")(attention_output)\n",
        "        \n",
        "    attention_output = keras.layers.Dropout(output_dropout, name=name and name + \"out_drop\")(attention_output) if output_dropout > 0 else attention_output\n",
        "    \n",
        "    return attention_output\n",
        "\n",
        "\n",
        "\n",
        "def block(inputs, out_channel, num_heads=0, attn_kernel_size=3, qkv_bias=True, mlp_ratio=4, mlp_drop_rate=0, attn_drop_rate=0, drop_rate=0, gamma=-1, activation=\"gelu\"):\n",
        "    is_conv = False if num_heads > 0 else True  # decide by if num_heads > 0\n",
        "    \n",
        "    input_channel = inputs.shape[-1]  # Same with out_channel\n",
        "    \n",
        "    pos_emb1 = depthwise_conv2d_no_bias(inputs, kernel_size=1, padding=\"SAME\", use_bias=True)\n",
        "    pos_emb2 = depthwise_conv2d_no_bias(inputs, kernel_size=3, padding=\"SAME\", use_bias=True)\n",
        "    pos_emb3 = depthwise_conv2d_no_bias(inputs, kernel_size=5, padding=\"SAME\", use_bias=True)\n",
        "    \n",
        "    pos_out = keras.layers.Add()([inputs, pos_emb1, pos_emb2, pos_emb3])\n",
        "\n",
        "    # print(f\">>>> {is_conv = }, {num_heads = }\")\n",
        "    if is_conv:\n",
        "        \n",
        "        attn = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(pos_out)\n",
        "        attn = conv2d_no_bias(attn, out_channel, 1, use_bias=True)\n",
        "        attn = depthwise_conv2d_no_bias(attn, kernel_size=5, padding=\"SAME\", use_bias=True)\n",
        "        attn = conv2d_no_bias(attn, out_channel, 1, use_bias=True)\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        attn = layer_norm(inputs)\n",
        "        attn = LWA(attn, attn_kernel_size, num_heads, attn_dropout=attn_drop_rate)\n",
        "        attn = ChannelAffine(use_bias=False, weight_init_value=gamma)(attn) if gamma >= 0 else attn\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    attn = drop_block(attn)\n",
        "    attn_out = keras.layers.Add()([inputs, pos_out,  attn])\n",
        "\n",
        "    if is_conv:\n",
        "        \n",
        "        mlp = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(attn_out)\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        mlp = keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPSILON)(attn_out)\n",
        "        \n",
        "    mlp = mlp_block(mlp, int(out_channel * mlp_ratio), activation=activation)\n",
        "    \n",
        "    mlp = ChannelAffine(use_bias=False, weight_init_value=gamma)(mlp) if gamma >= 0 else mlp\n",
        "    \n",
        "    \n",
        "    \n",
        "    return keras.layers.Add()([inputs, attn_out, mlp])\n",
        "\n",
        "\n",
        "def stem(inputs, stem_width, use_conv_stem=False, drop_rate=0, activation=\"gelu\"):\n",
        "    \n",
        "    if use_conv_stem:\n",
        "        \n",
        "        nn = conv2d_no_bias(inputs, stem_width // 2, kernel_size=3, strides=2, padding=\"same\", use_bias=True)\n",
        "        nn = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(nn)\n",
        "        nn = activation_by_name(nn, activation, name=name)\n",
        "        nn = conv2d_no_bias(nn, stem_width, kernel_size=3, strides=2, padding=\"same\", use_bias=True,)\n",
        "        nn = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(nn)\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        nn = conv2d_no_bias(inputs, stem_width, 4, strides=4, padding=\"valid\", use_bias=True)\n",
        "        nn = keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPSILON)(nn)\n",
        "        \n",
        "    \n",
        "    nn = keras.layers.Dropout(drop_rate) if drop_rate > 0 else nn\n",
        "    \n",
        "    return nn\n",
        "\n",
        "\n",
        "\n",
        "def FExtractor(inputs):\n",
        "    \n",
        "    \n",
        "    conv3d_shape = inputs.shape\n",
        "    x = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3],1))(inputs)\n",
        "    \n",
        "    x = Conv3D(filters=16, kernel_size=(1, 1, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv3D(filters=32, kernel_size=(1, 1, 5), activation='relu', padding='same')(x)\n",
        "\n",
        "    conv3d_shape = x.shape\n",
        "    x = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(x)\n",
        "    \n",
        "    ##### #################################    UNet     \n",
        "    \n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "   \n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(filters=32,kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(filters=32,kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x1 = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "    residual = layers.Conv2D(filters=32, kernel_size=(3, 3),strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "    x = layers.add([x1, residual])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "\n",
        "    x = layers.Activation(\"relu\")(x1)\n",
        "    x = layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "    residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "    residual = layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\")(residual)\n",
        "    x = layers.add([x, residual])  # Add back residual\n",
        " \n",
        "    return x\n",
        "\n",
        "\n",
        "def WetMapFormer(\n",
        "    num_blocks=[3, 4],\n",
        "    out_channels=[128, 256],\n",
        "    head_dimension=64,\n",
        "    use_conv_stem=False,\n",
        "    block_types=[\"conv\", \"transform\"],\n",
        "    stem_width=-1,\n",
        "    qkv_bias=True,\n",
        "    mlp_ratio=4,\n",
        "    layer_scale=-1,\n",
        "    mix_token=False,\n",
        "    token_label_top=False,\n",
        "    input_shape=(8, 8, 16,1),\n",
        "    num_classes=7,\n",
        "    activation=\"gelu\",\n",
        "    mlp_drop_rate=0,\n",
        "    attn_drop_rate=0,\n",
        "    drop_connect_rate=0,\n",
        "    dropout=0,\n",
        "    classifier_activation=\"softmax\",\n",
        "    pretrained=None,\n",
        "    model_name=\"WetMapFormer\",\n",
        "    kwargs=None,\n",
        "):\n",
        "    \n",
        "    inputs = keras.layers.Input(input_shape)\n",
        "    \n",
        "    augmented = data_augmentation(inputs)\n",
        "    \n",
        "    x=FExtractor(augmented)\n",
        "\n",
        "    \n",
        "    \"\"\" stem \"\"\"\n",
        "    stem_width = stem_width if stem_width > 0 else out_channels[0]\n",
        "    nn = stem(x, stem_width, use_conv_stem, drop_rate=mlp_drop_rate, activation=activation)  # It's using mlp_drop_rate for stem\n",
        "\n",
        "\n",
        "    \"\"\" stage [1, 2, 3, 4] \"\"\"\n",
        "    total_blocks = sum(num_blocks)\n",
        "    global_block_id = 0\n",
        "    for stack_id, (num_block, out_channel, block_type) in enumerate(zip(num_blocks, out_channels, block_types)):\n",
        "        stack_name = \"stack{}_\".format(stack_id + 1)\n",
        "        is_conv_block = True if block_type[0].lower() == \"c\" else False\n",
        "        num_heads = 0 if is_conv_block else out_channel // head_dimension\n",
        "        if stack_id > 0:\n",
        "            if use_conv_stem:\n",
        "                nn = conv2d_no_bias(nn, out_channel, kernel_size=3, strides=2, padding=\"same\", use_bias=True)\n",
        "                nn = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(nn)\n",
        "            else:\n",
        "                nn = conv2d_no_bias(nn, out_channel, kernel_size=2, strides=2, use_bias=True)\n",
        "                nn = keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPSILON)(nn)\n",
        "\n",
        "        for block_id in range(num_block):\n",
        "            block_drop_rate = drop_connect_rate * global_block_id / total_blocks\n",
        "            nn = block(nn, out_channel, num_heads, qkv_bias, mlp_ratio, attn_drop_rate, block_drop_rate, layer_scale, activation)\n",
        "            global_block_id += 1\n",
        "    nn = keras.layers.BatchNormalization(momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(nn)\n",
        "\n",
        "    \"\"\" output \"\"\"\n",
        "    if token_label_top and num_classes > 0:\n",
        "        # Training with label token\n",
        "        nn_cls = output_block(nn, num_classes=num_classes, classifier_activation=None)  # Don't use softmax here\n",
        "        nn_aux = keras.layers.Dense(num_classes)(nn)\n",
        "\n",
        "        if mix_token:\n",
        "            \n",
        "            nn_aux = mixup_token.do_mixup_token(nn_aux, bbox)\n",
        "            nn_aux = keras.layers.Reshape((-1, nn_aux.shape[-1]), dtype=\"float32\")(nn_aux)\n",
        "\n",
        "            left, top, right, bottom = bbox\n",
        "            lam = 1 - ((right - left) * (bottom - top) / (nn_aux.shape[1] * nn_aux.shape[2]))\n",
        "            lam_repeat = tf.expand_dims(tf.repeat(lam, tf.shape(nn_cls)[0], axis=0), 1)\n",
        "            nn_cls = keras.layers.Concatenate(axis=-1, dtype=\"float32\")([nn_cls, lam_repeat])\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            nn_aux = keras.layers.Reshape((-1, nn_aux.shape[-1]), dtype=\"float32\")(nn_aux)\n",
        "            \n",
        "        out = [nn_cls, nn_aux]\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        out = output_block(nn, num_classes=num_classes, classifier_activation=classifier_activation)\n",
        "\n",
        "    model = keras.models.Model(inputs, out, name=model_name)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def WetMapFormer_small(input_shape=(8, 8, 16), num_classes=7, classifier_activation=\"softmax\", token_label_top=False, **kwargs):\n",
        "    \n",
        "    num_blocks = [1, 1]\n",
        "    head_dimension = 32\n",
        "    \n",
        "    return WetMapFormer(**locals(), model_name=\"WetMapFormer_small\", **kwargs)\n",
        "\n",
        "def WetMapFormer_medium(input_shape=(8, 8, 16), num_classes=7, classifier_activation=\"softmax\", token_label_top=False, **kwargs):\n",
        "    \n",
        "    num_blocks = [3, 4]\n",
        "    head_dimension = 256\n",
        "    \n",
        "    return WetMapFormer(**locals(), model_name=\"WetMapFormer_medium\", **kwargs)\n",
        "\n",
        "\n",
        "def WetMapFormer_large(input_shape=(8, 8, 16), num_classes=7, classifier_activation=\"softmax\", token_label_top=False, **kwargs):\n",
        "    \n",
        "    num_blocks = [6, 8]\n",
        "    head_dimension = 1024\n",
        "    \n",
        "    return WetMapFormer(**locals(), model_name=\"WetMapFormer_large\", **kwargs)"
      ],
      "metadata": {
        "id": "CAFsVm-9EDBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = WetMapFormer_small(input_shape=(8, 8, 16), num_classes=7)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "l08lML2rEKBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "32XvhfcfEKEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "dropout_rate = 0.4\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "gmtQCTwjEKG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "checkpoint_filepath = \"E:/WetMapFormer.h5\"\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "history = model.fit(\n",
        "        x=Xtrain,\n",
        "        y=ytrain,\n",
        "        batch_size=batch_size,\n",
        "        epochs=100,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )"
      ],
      "metadata": {
        "id": "OPNkt2LcEKJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest = Xtest.reshape(-1, 8, 8, 16,1)\n"
      ],
      "metadata": {
        "id": "aSsEO92bEUK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "from operator import truediv\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_matrix):\n",
        "    counter = confusion_matrix.shape[0]\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return average_acc\n",
        "\n",
        "\n",
        "Y_pred = model.predict(Xtest)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "confusion = confusion_matrix(ytest, y_pred)\n",
        "oa = accuracy_score(ytest, y_pred)\n",
        "aa = AA_andEachClassAccuracy(confusion)\n",
        "kappa = cohen_kappa_score(ytest, y_pred)\n",
        "\n",
        "\n",
        "oa, aa, kappa"
      ],
      "metadata": {
        "id": "qhW6ZoAiEV4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jxkpJ0kEV71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrnGmpChEV-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8gWxeU-D-j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WN_ipu_9Do1l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}